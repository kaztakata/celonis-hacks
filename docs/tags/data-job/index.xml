<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Job on Celonis hacks</title>
    <link>https://kaztakata.github.io/celonis-hacks/tags/data-job/</link>
    <description>Recent content in Data Job on Celonis hacks</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 18 Dec 2021 09:22:56 +0900</lastBuildDate>
    
	<atom:link href="https://kaztakata.github.io/celonis-hacks/tags/data-job/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Use Pseudonymized Column as Grouping Key</title>
      <link>https://kaztakata.github.io/celonis-hacks/posts/2021-12-18-use-pseudonymized-column-as-grouping-key/</link>
      <pubDate>Sat, 18 Dec 2021 09:22:56 +0900</pubDate>
      
      <guid>https://kaztakata.github.io/celonis-hacks/posts/2021-12-18-use-pseudonymized-column-as-grouping-key/</guid>
      <description>One of the biggest headache for data engineer like me is how to assure data security when extracting data. Especially personal information should be dealt sensitively, otherwise I may be punished by each region&amp;rsquo;s law (e.g. GDPR).
When I operate Celonis EMS, I try not to extract sensitive information from the beginning, for example I do not extract table of customer address (ADRC table in SAP etc.). But this information is sometimes effective for grouping key of counting case etc.</description>
    </item>
    
    <item>
      <title>Understand Delta Load Configuration Difference in Adding Column Scenario</title>
      <link>https://kaztakata.github.io/celonis-hacks/posts/2021-12-11-understand-delta-load-configuration-difference-in-adding-column-scenario/</link>
      <pubDate>Sat, 11 Dec 2021 21:54:02 +0900</pubDate>
      
      <guid>https://kaztakata.github.io/celonis-hacks/posts/2021-12-11-understand-delta-load-configuration-difference-in-adding-column-scenario/</guid>
      <description>Last time I showed behavior when I added new record then extracted that record by Delta Load (Verify Cloning Table Contents via Delta Load). Delta Load is effective way to minimize extraction effort, but it is not always applied. Today, it is continued from previous post, I would like to add column to cloned table and observe behavior of extraction task.
After starting system operation including database, normally system is changing its requirement and extend function and database etc.</description>
    </item>
    
    <item>
      <title>Verify Cloning Table Contents via Delta Load</title>
      <link>https://kaztakata.github.io/celonis-hacks/posts/2021-12-04-verify-cloning-table-contents-via-delta-load/</link>
      <pubDate>Sat, 04 Dec 2021 12:49:44 +0900</pubDate>
      
      <guid>https://kaztakata.github.io/celonis-hacks/posts/2021-12-04-verify-cloning-table-contents-via-delta-load/</guid>
      <description>Following last week&amp;rsquo;s Minimize Extraction Time by Delta Load Option, today I would like to insert new record to Postgres table then try Delta Load again to extract it. To do this, I will start from operating pgAdmin, that is already ready for my loal machine after docker-compose.
First step is to enter localhost:5050 to my browser, then at the login screen enter pgadmin@celonis.cloud as email and pgadmin as password then click login button.</description>
    </item>
    
    <item>
      <title>Minimize Extraction Time by Delta Load Option</title>
      <link>https://kaztakata.github.io/celonis-hacks/posts/2021-11-27-minimize-extraction-time-by-delta-load-option/</link>
      <pubDate>Sat, 27 Nov 2021 09:51:19 +0900</pubDate>
      
      <guid>https://kaztakata.github.io/celonis-hacks/posts/2021-11-27-minimize-extraction-time-by-delta-load-option/</guid>
      <description>Last week I extracted Postgres table and looked at the log to understand mechanism of data transfer. At that time I used Full Load option to extract data, that is to replace all table contents and schema to latest version. That is easiest way to synchronize tables between source system (Postgres) and Celonis, but it takes a lot of time to complete this task. So that I should also use second option Delta Load to minimize extraction time.</description>
    </item>
    
    <item>
      <title>Look at Data Transfer Process by Data Job Log</title>
      <link>https://kaztakata.github.io/celonis-hacks/posts/2021-11-20-look-at-data-transfer-process-by-data-job-log/</link>
      <pubDate>Sat, 20 Nov 2021 08:39:24 +0900</pubDate>
      
      <guid>https://kaztakata.github.io/celonis-hacks/posts/2021-11-20-look-at-data-transfer-process-by-data-job-log/</guid>
      <description>Last week I posted Connect to Celonis and Bring Back Instruction to look at how Extractor works to connect between Celonis and Postgres. This week I would like to extract data from Postgres and look at data transfer process by data job log.
In the Data Integration, I create new Data Job with Data Connection I created last week, then create new extraction task. In the next screen I add new table public.</description>
    </item>
    
  </channel>
</rss>